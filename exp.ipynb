{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_raster_to_slu(raster, slope_units, reduce_fn=np.mean, get_im=False):\n",
    "    raster = raster.astype(np.float32)\n",
    "    n_units = len(np.unique(slope_units))\n",
    "    feature_table = np.zeros(n_units, dtype=raster.dtype)\n",
    "    for i in range(n_units):\n",
    "        if np.any(slope_units == i+1) == 0:\n",
    "            continue\n",
    "        feature_table[i] = reduce_fn(raster[slope_units == i+1])\n",
    "    if get_im:\n",
    "        feature_im = np.zeros_like(raster)\n",
    "        for i in range(n_units):\n",
    "            if np.any(slope_units == i+1) == 0:\n",
    "                continue\n",
    "            feature_im[slope_units == i+1] = feature_table[i]\n",
    "        return feature_table, feature_im\n",
    "    return feature_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_region_slopeunits(raw_dir, region_id, min_count, out_dir):\n",
    "\n",
    "    with open(f'{raw_dir}/{region_id}.pkl', 'rb') as f:\n",
    "        region = pickle.load(f)\n",
    "\n",
    "    slopeunits = region['slopeunits']\n",
    "    y = region['inventory']\n",
    "    X = region['features']\n",
    "    feature_names = region['names']\n",
    "    metadata = region['metadata']\n",
    "\n",
    "    y_slu = map_raster_to_slu(y, slopeunits, reduce_fn=np.mean)\n",
    "    counts_slu = map_raster_to_slu(np.ones_like(y), slopeunits, reduce_fn=np.sum)\n",
    "\n",
    "    extreme_features = ['slope', 'curv_mean', 'curv_total', 'curv_profile', 'drainage_area']\n",
    "    feats, new_feat_names = [], []\n",
    "    for i, feat in enumerate(feature_names):\n",
    "        feat_mean = map_raster_to_slu(X[i], slopeunits, reduce_fn=np.mean)\n",
    "        feat_var = map_raster_to_slu(X[i], slopeunits, reduce_fn=np.var)\n",
    "        feats += [feat_mean, feat_var]\n",
    "        new_feat_names += [f'{feat}_mean', f'{feat}_var']\n",
    "        if feat in extreme_features:\n",
    "            feat_min = map_raster_to_slu(X[i], slopeunits, reduce_fn=np.min)\n",
    "            feat_max = map_raster_to_slu(X[i], slopeunits, reduce_fn=np.max)\n",
    "            feats += [feat_min, feat_max]\n",
    "            new_feat_names += [f'{feat}_min', f'{feat}_max']\n",
    "    feats = np.stack(feats)\n",
    "\n",
    "    mask = counts_slu >= min_count\n",
    "    feats = feats[:,mask]\n",
    "    y_slu = y_slu[mask]\n",
    "    counts_slu = counts_slu[mask]\n",
    "    X_slu = pd.DataFrame(feats, index=new_feat_names).T\n",
    "\n",
    "    data_dict = {\n",
    "        'X': X_slu,\n",
    "        'y': y_slu,\n",
    "        'counts': counts_slu,\n",
    "        'slope_units': slopeunits,\n",
    "        'metadata': metadata,\n",
    "    }\n",
    "\n",
    "    with open(f'{out_dir}/{region_id}.pkl', 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
